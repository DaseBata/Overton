{"policy_document_id": "councilofeurope-a81d7ea91428629fdf6f886f4c1c8e84", "pdf_document_id": "councilofeurope-a81d7ea91428629fdf6f886f4c1c8e84-d6057afeedf9ea688bbccbe99e0d3636", "es_score": 7.7580185, "overton_url": "http://app.overton.io/document.php?policy_document_id=councilofeurope-a81d7ea91428629fdf6f886f4c1c8e84", "overton_url_with_context": "http://app.overton.io/document.php?policy_document_id=councilofeurope-a81d7ea91428629fdf6f886f4c1c8e84", "title": "\u00c9tude sur l\u2019impact des syst\u00e8mes d\u2019intelligence artificielle, leur potentiel de promotion de l\u2019\u00e9galit\u00e9, y compris l\u2019\u00e9galit\u00e9 de genre, et les risques qu\u2019ils peuvent entra\u00eener en mati\u00e8re de non-discrimination", "translated_title": "Study on the impact of artificial intelligence systems, their potential to promote equality, including gender equality, and the risks they may pose in terms of non-discrimination", "source": {"source_id": "councilofeurope", "title": "Council of Europe", "country": "IGO", "type": "igo", "subtype": null, "region": ["International Organizations", "Non-OECD members"]}, "citation_count": 0, "citation_count_including_self": 0, "authors": ["Council of Europe"], "authors_are_organizations": true, "snippet": "", "published_on": "2023-08-07", "added_on": "2023-09-15", "document_url": "https://edoc.coe.int/en/artificial-intelligence/11646-study-on-the-impact-of-artificial-intelligence-systems-their-potential-for-promoting-equality-including-gender-equality-and-the-risks-they-may-cause-in-relation-to-non-discrimination.html", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=ac8645c4e666d447670bebf90cf8fbc2&k=cbe651e0241385f4082a08119f51bc05", "thumbnail": "http://app.overton.io/cache_image/pdf_thumbnails/councilofeurope/2034c4d0e199d2356c73141b0e8efc67.png", "thumbnail_path": "cache_image/pdf_thumbnails/councilofeurope/2034c4d0e199d2356c73141b0e8efc67.png", "topics": ["European Convention on Human Rights", "Artificial intelligence", "Istanbul Convention", "Machine learning", "Discrimination", "European Union", "Branches of science", "Employment discrimination", "Sexism", "European Charter for Regional or Minority Languages", "Gender", "Issues in ethics", "Facial recognition system", "Council of Europe", "Social issues", "Hate speech", "Politics", "Intelligence", "Justice"], "dont_show_pdf": "false", "classifications": ["society>discrimination", "society", "crime, law and justice", "politics", "science and technology", "crime, law and justice>law"], "source_tags": [], "overton_policy_document_series": "Publication", "other_identifiers": [], "languages": ["fre"], "cites": {"scholarly": [{"doi": "10.2838/77444", "title": null, "publisher": null}, {"doi": "10.5325/jinfopoli.8.2018.0078", "title": "How Algorithms Discriminate Based on Data They Lack: Challenges, Solutions, and Policy Implications", "journal": "Journal of Information Policy", "publisher": "The Pennsylvania State University Press"}, {"doi": "10.1093/ojls/gqab006", "title": "Challenging Biased Hiring Algorithms", "journal": "Oxford Journal of Legal Studies", "publisher": "Oxford University Press (OUP)"}, {"doi": "10.54648/cola2021005", "title": "In search of effectiveness and fairness in proving algorithmic discrimination in EU law", "journal": "Common Market Law Review", "publisher": "Kluwer Law International BV"}, {"doi": "10.2838/447194", "title": null, "publisher": null}, {"doi": "10.1145/3375627.3375841", "title": "Contextual Analysis of Social Media", "publisher": "ACM"}, {"doi": "10.1177/1023263x20982173", "title": "Tuning EU equality law to algorithmic discrimination: Three pathways to resilience", "journal": "Maastricht Journal of European and Comparative Law", "publisher": "SAGE Publications"}, {"doi": "10.1007/s00146-022-01553-5,etoms,ageisminartificialintelligenceforhealth(2022)", "title": null, "publisher": null}, {"doi": "10.5210/fm.v26i8.11717", "title": "Gendered language and employment Web sites: How search algorithms can cause allocative harm", "journal": "First Monday", "publisher": "University of Illinois Libraries"}, {"doi": "10.2139/ssrn.4104823(derni\u00e8reconsultationle28juillet2022)", "title": null, "publisher": null}, {"doi": "10.1145/3465416.3483305", "title": "A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle", "publisher": "ACM"}, {"doi": "10.2838/6934", "title": null, "publisher": null}, {"doi": "10.1093/icon/moaa031", "title": "Resurrecting positive action", "journal": "International Journal of Constitutional Law", "publisher": "Oxford University Press (OUP)"}, {"doi": "10.2139/ssrn.983685(derni\u00e8reconsultationle28juillet2022)", "title": null, "publisher": null}, {"doi": "10.1016/j.clsr.2021.105561", "title": "An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems", "journal": "Computer Law & Security Review", "publisher": "Elsevier BV"}, {"doi": "10.1093/idpl/ipx005", "title": "Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation", "journal": "International Data Privacy Law", "publisher": "Oxford University Press (OUP)"}, {"doi": "10.1177/14614448211023772", "title": "Ms. Categorized: Gender, notability, and inequality on Wikipedia", "journal": "New Media & Society", "publisher": "SAGE Publications"}], "policy": [{"overton_id": "unesco-f780229f1a645fb02583ffb6601d5c23", "title": "I'd blush if I could: closing gender divides in digital skills through education", "policy_source_id": "unesco"}, {"overton_id": "europa-d3b8fa8e39cf622cbcbca6f66a8f68c8", "title": "Algorithmic discrimination in Europe : challenges and opportunities for gender equality and non-discrimination law.", "policy_source_id": "europa"}, {"overton_id": "councilofeurope-63c60ea23ad892349d8fe357141b2074", "title": "Lignes directrices sur la reconnaissance faciale", "policy_source_id": "councilofeurope"}, {"overton_id": "govuk-0e6c23a352d2af62a9da0182f7c758cc", "title": "Findings from the DRCF Algorithmic Processing workstream - Spring 2022", "policy_source_id": "govuk"}, {"overton_id": "ainow-ee8c5b373d48f5829cf9853208b436b2", "title": "Discriminating Systems: Gender, Race, and Power in AI - Report", "policy_source_id": "ainow"}, {"overton_id": "amnesty-6165fc767103434429bf8e62a3ae0346", "title": "Netherlands: We sense trouble: Automated discrimination and mass surveillance in predictive policing in the Netherlands", "policy_source_id": "amnesty"}, {"overton_id": "govuk-54dbd696269180fa2faeb8bdaf5f339d", "title": "Data: a new direction", "policy_source_id": "govuk"}, {"overton_id": "europa-47b4ecd73de29696ca09ed6d754818c5", "title": "Analysis and comparative review of equality data collection practices in the European Union : legal framework and practice in the EU Member States.", "policy_source_id": "europa"}], "news": [{"reference_string": "111. Kari Paul, \u2018Disastrous\u2019 lack of diversity in AI industry perpetuates bias, study finds, The Guardian, 17 April 2019: https://www.theguardian.com/technology/2019/apr/16/artificial-intelligence-lack-diversity-new-york-university-study (derni\u00e8re consultation le 27 juillet 2022).", "matched_news_url": "https://www.theguardian.com/technology/2019/apr/16/artificial-intelligence-lack-diversity-new-york-university-study", "matched_news_outlet": "The Guardian"}, {"reference_string": "46. Voir Buolamwini J et Gebru T, Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification (Proceedings of Machine Learning Research 2018) ; Hannah Devlin, \u00ab AI systems claiming to \u2018read\u2019 emotions pose discrimination risks \u00bb (16 f\u00e9vrier 2020), The Guardian : https://www.theguardian.com/technology/2020/feb/16/ ai-systems-claiming-to-read-emotions-pose-discrimination-risks (derni\u00e8re consultation le 22 juillet 2022).", "matched_news_url": "https://www.theguardian.com/technology/2020/feb/16/", "matched_news_outlet": "The Guardian"}, {"reference_string": "25. Samuel Gibbs, Women less likely to be shown ads for high-paid jobs on Google, study shows, The Guardian, 8 juillet 2015 : https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study (derni\u00e8re consultation : 15 juin 2022).", "matched_news_url": "https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study", "matched_news_outlet": "The Guardian"}, {"reference_string": "24. Apple\u2019s \u2018sexist\u2019 credit card investigated by US regulator, BBC, 11 novembre 2019: https://www.bbc.com/news/business-50365609 (derni\u00e8re consultation : 15 juin 2022).", "matched_news_url": "https://www.bbc.com/news/business-50365609", "matched_news_outlet": "BBC News"}, {"reference_string": "6. Alisha Haridasani Gupta, \u201cAre Algorithms Sexist?\u201d The New York Times (15 November 2019) available at: https://www.nytimes.com/2019/11/15/us/apple-card-goldman-sachs.html (last accessed: 25 juillet 2022).", "matched_news_url": "https://www.nytimes.com/2019/11/15/us/apple-card-goldman-sachs.html", "matched_news_outlet": "The New York Times"}, {"reference_string": "5. Amazon scraps secret AI recruiting tool that showed bias against women, Reuters, 11 octobre 2018 : https://www.reuters.com/article/us-amazon-com-jobs-automation-insightidUSKCN1MK08G (derni\u00e8re consultation le 25 juillet 2022).", "matched_news_url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insightidUSKCN1MK08G", "matched_news_outlet": "Reuters"}, {"reference_string": "3. Melissa Heikkila, Dutch scandal serves as a warning for Europe over risks of using algorithms, Politico, 29 mars 2022, voir : https://www.politico.eu/article/dutch-scandal-serves-as-awarning-for-europe-over-risks-of-using-algorithms/ (derni\u00e8re consultation le 30 ao\u00fbt 2022)", "matched_news_url": "https://www.politico.eu/article/dutch-scandal-serves-as-awarning-for-europe-over-risks-of-using-algorithms/", "matched_news_outlet": "Politico"}, {"reference_string": "41. Voir Dastin J, \u2018Amazon scraps secret AI recruiting tool that showed bias against women\u2019 Reuters (2018): https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-airecruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G (derni\u00e8re consultation le 22 juillet 2022).", "matched_news_url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-airecruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G", "matched_news_outlet": "Reuters"}, {"reference_string": "63. Jon Henley, \u201cDutch government faces collapse over child benefits scandal \u201d (14 January 2021) The Guardian: https://www.theguardian.com/world/2021/jan/14/dutch-governmentfaces-collapse-over-child-benefits-scandal and Bj\u00f6rn ten Seldam & Alex Brenninkmeijer, \u201cThe Dutch benefits scandal: a cautionary tale for algorithmic enforcement\u201d (30 April 2021) EU Law Enforcement: https://eulawenforcement.com/?p=7941.", "matched_news_url": "https://www.theguardian.com/world/2021/jan/14/dutch-governmentfaces-collapse-over-child-benefits-scandal", "matched_news_outlet": "The Guardian"}, {"reference_string": "55. Voir JD Shadel, \u00ab #TravelingWhileTrans : The trauma of returning to \u2018normal\u2019 \u00bb (The Washington Post, 2021) : https://www.washingtonpost.com/travel/2021/06/16/trans-travel-tsa-lgbtq/ and Quinan, C. L., and Mina Hunt. \u00ab Biometric Bordering and Automatic Gender Recognition : Challenging Binary Gender Norms in Everyday Biometric Technologies. \u201cCommunication, Culture and Critique 15.2 (2022) : 211-226.", "matched_news_url": "https://www.washingtonpost.com/travel/2021/06/16/trans-travel-tsa-lgbtq/", "matched_news_outlet": "The Washington Post"}], "people": [{"person": "Kate Crawford", "affiliation": "New York University", "snippet": "109. Sarah Myers West, Meredith Whittaker et Kate Crawford, Discriminating Systems : Gender,\nRace, and Power in AI, AI Now Institute NYU, April 2019 : https://ainowinstitute.org/discriminatingsystems.pdf\n(derni\u00e8re consultation : 27 juillet 2022)."}, {"person": "Meredith Whittaker", "affiliation": "New York University", "snippet": "109. Sarah Myers West, Meredith Whittaker et Kate Crawford, Discriminating Systems : Gender,\nRace, and Power in AI, AI Now Institute NYU, April 2019 : https://ainowinstitute.org/discriminatingsystems.pdf\n(derni\u00e8re consultation : 27 juillet 2022)."}]}, "highlights": [{"type": "text", "text": "par des plateformes de r\u00e9seaux sociaux telles que Facebook vientaussi renforcer les st\u00e9r\u00e9otypes de genre ainsi que la s\u00e9gr\u00e9gation de genre    40. Eric Hal Schwartz, OpenAI Promises Customizable ChatGPT After Bias Complaints, 20f\u00e9vrier 2023 : https://voicebot.ai/2023/02/20/openai-promises-customizable-chatgpt-after-bias-complaints/.    41. Voir Dastin J, Amazon scraps secret AI recruiting tool that showed bias against womenReuters 2018: https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=ac8645c4e666d447670bebf90cf8fbc2&k=cbe651e0241385f4082a08119f51bc05", "pdf_title": "PDF #1", "page": "24"}, {"type": "text", "text": "moins de 19  de ces biographies sont celles de femmes 39 . On peut\u00e9galement sinterroger sur la diversit\u00e9 du personnel charg\u00e9 d\u00e9tiqueter lesdonn\u00e9es. Enfin, les id\u00e9es qui circulent sur les mod\u00e8les personnalis\u00e9s pouvantse substituer au mod\u00e8le unique ChatGPT afin que les valeurs que nous    37. Voir Green B et Chen Y,  Disparate interactions : An algorithm-in-the-loop analysis of fairnessin risk assessments  2019 Actes de la conf\u00e9rence sur l\u00e9quit\u00e9, la responsabilit\u00e9 et latransparence 90.  ", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=ac8645c4e666d447670bebf90cf8fbc2&k=cbe651e0241385f4082a08119f51bc05", "pdf_title": "PDF #1", "page": "23"}]}
