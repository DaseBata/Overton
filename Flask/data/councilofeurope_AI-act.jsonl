{"policy_document_id": "councilofeurope-7018c906ea9ad1d2851d73b46a5d3938", "pdf_document_id": "councilofeurope-7018c906ea9ad1d2851d73b46a5d3938-73968fc1dd6e9ceec86cda37ab60c1ee", "es_score": 7.4739113, "overton_url": "http://app.overton.io/document.php?policy_document_id=councilofeurope-7018c906ea9ad1d2851d73b46a5d3938", "overton_url_with_context": "http://app.overton.io/document.php?policy_document_id=councilofeurope-7018c906ea9ad1d2851d73b46a5d3938", "title": "Study on the impact of artificial intelligence systems, their potential for promoting equality, including gender equality, and the risks they may cause in relation to non-discrimination", "translated_title": "", "source": {"source_id": "councilofeurope", "title": "Council of Europe", "country": "IGO", "type": "igo", "subtype": null, "region": ["International Organizations", "Non-OECD members"]}, "citation_count": 0, "citation_count_including_self": 0, "authors": ["Council of Europe"], "authors_are_organizations": true, "snippet": "", "published_on": "2023-08-23", "added_on": "2023-09-15", "document_url": "https://edoc.coe.int/en/artificial-intelligence/11649-study-on-the-impact-of-artificial-intelligence-systems-their-potential-for-promoting-equality-including-gender-equality-and-the-risks-they-may-cause-in-relation-to-non-discrimination.html", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=6595d842ae9e6c1ecfd9f976dcb8e058&k=cbe651e0241385f4082a08119f51bc05", "thumbnail": "http://app.overton.io/cache_image/pdf_thumbnails/councilofeurope/126f312cce079d4ce601fd7d66e1e748.png", "thumbnail_path": "cache_image/pdf_thumbnails/councilofeurope/126f312cce079d4ce601fd7d66e1e748.png", "topics": ["Justice", "Algorithmic bias", "Artificial intelligence", "Facial recognition system", "Online hate speech", "European Convention on Human Rights", "Istanbul Convention", "Sexism", "Machine learning", "Discrimination", "Bias", "Automated decision-making", "Violence against women", "Gender inequality", "European Union", "Governance", "Minority group", "Social issues", "Branches of science", "Issues in ethics", "Gender", "Committee of Ministers of the Council of Europe", "Anti-discrimination law", "European Court of Human Rights", "Technology", "Politics", "Information", "Risk", "Intersectionality", "Research", "Law", "Violence", "Gender equality", "Cognition", "DALL-E", "General Data Protection Regulation", "Human rights", "Stereotype", "Proxy server", "Recruitment", "Algorithm", "Domestic violence", "Data", "Social media", "European Union law", "Privacy", "Social exclusion", "Asylum seeker", "Online gender-based violence", "Confirmation bias", "Decision-making"], "dont_show_pdf": "false", "classifications": ["society", "economy, business and finance", "economy, business and finance>economic sector", "society>discrimination", "economy, business and finance>economic sector>computing and information technology", "health", "politics", "science and technology"], "source_tags": [], "overton_policy_document_series": "Publication", "other_identifiers": [], "languages": ["eng"], "cites": {"scholarly": [{"doi": "10.2139/ssrn.983685", "title": "Processing Data on Racial or Ethnic Origin for Antidiscrimination Policies: How to Reconcile the Promotion of Equality with the Right to Privacy?", "journal": "SSRN Electronic Journal", "publisher": "Elsevier BV"}, {"doi": "10.1145/3375627.3375841", "title": "Contextual Analysis of Social Media", "publisher": "ACM"}, {"doi": "10.2838/77444", "title": null, "publisher": null}, {"doi": "10.54648/cola2021005", "title": "In search of effectiveness and fairness in proving algorithmic discrimination in EU law", "journal": "Common Market Law Review", "publisher": "Kluwer Law International BV"}, {"doi": "10.5325/jinfopoli.8.1.0078", "title": "How Algorithms Discriminate Based on Data They Lack: Challenges, Solutions, and Policy Implications", "journal": "Journal of Information Policy", "publisher": "The Pennsylvania State University Press"}, {"doi": "10.1177/0967010614544204", "title": "The new profiling: Algorithms, black boxes, and the failure of anti-discriminatory safeguards in the European Union", "journal": "Security Dialogue", "publisher": "SAGE Publications"}, {"doi": "10.1016/j.clsr.2021.105561", "title": "An evidence-based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems", "journal": "Computer Law & Security Review", "publisher": "Elsevier BV"}, {"doi": "10.1177/1023263x20982173", "title": "Tuning EU equality law to algorithmic discrimination: Three pathways to resilience", "journal": "Maastricht Journal of European and Comparative Law", "publisher": "SAGE Publications"}, {"doi": "10.2838/447194", "title": null, "publisher": null}, {"doi": "10.1080/13600869.2017.1298547", "title": "Accountability for the use of algorithms in a big data environment", "journal": "International Review of Law, Computers & Technology", "publisher": "Informa UK Limited"}, {"doi": "10.1093/ojls/gqab006", "title": "Challenging Biased Hiring Algorithms", "journal": "Oxford Journal of Legal Studies", "publisher": "Oxford University Press (OUP)"}, {"doi": "10.1093/icon/moaa031", "title": "Resurrecting positive action", "journal": "International Journal of Constitutional Law", "publisher": "Oxford University Press (OUP)"}, {"doi": "10.1145/3465416.3483305", "title": "A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle", "publisher": "ACM"}, {"doi": "10.2307/3312446", "title": "Negligent Discrimination", "journal": "University of Pennsylvania Law Review", "publisher": "JSTOR"}, {"doi": "10.1177/14614448211023772", "title": "Ms. Categorized: Gender, notability, and inequality on Wikipedia", "journal": "New Media & Society", "publisher": "SAGE Publications"}, {"doi": "10.1215/07402775-3813015", "title": "Racist in the Machine", "journal": "World Policy Journal", "publisher": "Duke University Press"}, {"doi": "10.2838/6934", "title": null, "publisher": null}, {"doi": "10.1016/s0262-4079(22)01329-x", "title": "AI art tool covertly alters requests", "journal": "New Scientist", "publisher": "Elsevier BV"}, {"doi": "10.1111/1468-2230.12759", "title": "Directly Discriminatory Algorithms", "journal": "Modern Law Review", "publisher": "Wiley"}, {"doi": "10.2139/ssrn.4104823", "title": "Using Sensitive Data to Prevent Discrimination by AI: Does the GDPR Need a New Exception?", "journal": "SSRN Electronic Journal", "publisher": "Elsevier BV"}, {"doi": "10.1007/s00146-022-01553-5", "title": "AI ageism: a critical roadmap for studying age discrimination and exclusion in digitalized societies", "journal": "AI & SOCIETY", "publisher": "Springer Science and Business Media LLC"}, {"doi": "10.1093/idpl/ipx005", "title": "Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation", "journal": "International Data Privacy Law", "publisher": "Oxford University Press (OUP)"}], "policy": [{"overton_id": "europarl_debates-4eff873e66ecec5522fcdb07b301ec77", "title": "What is artificial intelligence and how is it used?", "policy_source_id": "europarl_debates"}, {"overton_id": "airegulation-28618e245471780c9fb074baa357afaa", "title": "Study on Understanding algorithmic decision-making", "policy_source_id": "airegulation"}, {"overton_id": "stoa-7bd471194ab24389253a2fe44fc51597", "title": "Governing data and artificial intelligence for all: Models for sustainable and just data governance | Panel for the Future of Science and Technology (STOA) | European Parliament", "policy_source_id": "stoa"}, {"overton_id": "councilofeurope-9d22e3044df8670cf3f85afa66fdbfeb", "title": "Guidelines on facial recognition", "policy_source_id": "councilofeurope"}, {"overton_id": "europa-d3b8fa8e39cf622cbcbca6f66a8f68c8", "title": "Algorithmic discrimination in Europe : challenges and opportunities for gender equality and non-discrimination law.", "policy_source_id": "europa"}, {"overton_id": "councilofeurope-e6baede7f29178a658ce4c8f5e1b222d", "title": "PDF - Handbook on European non-discrimination law (2018 edition)", "policy_source_id": "councilofeurope"}, {"overton_id": "ainow-ee8c5b373d48f5829cf9853208b436b2", "title": "Discriminating Systems: Gender, Race, and Power in AI - Report", "policy_source_id": "ainow"}, {"overton_id": "councilofeurope-0082c5141f6958bf715f2cc4b9eb1aa3", "title": "Artificial intelligence, human rights, democracy, and the rule of law - A primer", "policy_source_id": "councilofeurope"}, {"overton_id": "eucommission-417f055addde6888bb7f68f0a384f53a", "title": "Proposal for a Directive of the European Parliament and of the", "policy_source_id": "eucommission"}, {"overton_id": "councilofeurope-0cd8fd969f66568988772810a567e90b", "title": "Council of Europe Gender Equality Strategy 2018-2023", "policy_source_id": "councilofeurope"}, {"overton_id": "airegulation-b0f948b29510e8ea775a715a986942df", "title": "Study on Discrimination, artificial intelligence, and algorithmic decision-making", "policy_source_id": "airegulation"}, {"overton_id": "airegulation-289f9788ce8acda1262698b06099bf58", "title": "Guidelines on Artificial Intelligence and Data Protection", "policy_source_id": "airegulation"}, {"overton_id": "europa-47b4ecd73de29696ca09ed6d754818c5", "title": "Analysis and comparative review of equality data collection practices in the European Union : legal framework and practice in the EU Member States.", "policy_source_id": "europa"}, {"overton_id": "amnesty-6165fc767103434429bf8e62a3ae0346", "title": "Netherlands: We sense trouble: Automated discrimination and mass surveillance in predictive policing in the Netherlands", "policy_source_id": "amnesty"}, {"overton_id": "govuk-54dbd696269180fa2faeb8bdaf5f339d", "title": "Data: a new direction", "policy_source_id": "govuk"}, {"overton_id": "unesco-f780229f1a645fb02583ffb6601d5c23", "title": "I'd blush if I could: closing gender divides in digital skills through education", "policy_source_id": "unesco"}, {"overton_id": "councilofeurope-95453630fc5f1dbebe6f532fbc2dc05c", "title": "Protecting the rights of migrant, refugee and asylum-seeking women and girls -Recommendation CM/Rec(2022)17", "policy_source_id": "councilofeurope"}], "news": [{"reference_string": "25. Samuel Gibbs, Women less likely to be shown ads for high-paid jobs on Google, study shows, The Guardian, 8 July 2015, available at: https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study (last accessed: 15 June 2022).", "matched_news_url": "https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study", "matched_news_outlet": "The Guardian"}, {"reference_string": "24. Apple\u2019s \u2018sexist\u2019 credit card investigated by US regulator, BBC, 11 November 2019, available at: https://www.bbc.com/news/business-50365609 (last accessed: 15 June 2022).", "matched_news_url": "https://www.bbc.com/news/business-50365609", "matched_news_outlet": "BBC News"}, {"reference_string": "111. Kari Paul, \u2018Disastrous\u2019 lack of diversity in AI industry perpetuates bias, study finds, The Guardian, 17 April 2019, available at: https://www.theguardian.com/technology/2019/apr/16/artificial-intelligence-lack-diversity-new-york-university-study (last accessed: 27 July 2022).", "matched_news_url": "https://www.theguardian.com/technology/2019/apr/16/artificial-intelligence-lack-diversity-new-york-university-study", "matched_news_outlet": "The Guardian"}, {"reference_string": "55. See JD Shadel, \u201c#TravelingWhileTrans: The trauma of returning to \u2018normal\u2019\u201d (The Washington Post, 2021) available at: https://www.washingtonpost.com/travel/2021/06/16/trans-traveltsa-lgbtq/ and Quinan, C. L., and Mina Hunt. \u201cBiometric Bordering and Automatic Gender Recognition: Challenging Binary Gender Norms in Everyday Biometric Technologies.\u201d Communication, Culture and Critique 15.2 (2022): 211-226.", "matched_news_url": "https://www.washingtonpost.com/travel/2021/06/16/trans-traveltsa-lgbtq/", "matched_news_outlet": "The Washington Post"}, {"reference_string": "46. See Buolamwini J and Gebru T, Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification (Proceedings of Machine Learning Research 2018); Hannah Devlin, \u201cAI systems claiming to \u2018read\u2019 emotions pose discrimination risks\u201d (16 February 2020) The Guardian available at: https://www.theguardian.com/technology/2020/ feb/16/ai-systems-claiming-to-read-emotions-pose-discrimination-risks (last accessed 22 July 2022).", "matched_news_url": "https://www.theguardian.com/technology/2020/", "matched_news_outlet": "The Guardian"}, {"reference_string": "41. See Dastin J, \u2018Amazon scraps secret AI recruiting tool that showed bias against women\u2019 Reuters (2018) available at: https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-airecruiting-tool-that-showed-bias-against-womenidUSKCN1MK08G (last accessed 22 July 2022).", "matched_news_url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-airecruiting-tool-that-showed-bias-against-womenidUSKCN1MK08G", "matched_news_outlet": "Reuters"}, {"reference_string": "6. Alisha Haridasani Gupta, \u201cAre Algorithms Sexist?\u201d The New York Times (15 November 2019) available at: https://www.nytimes.com/2019/11/15/us/apple-card-goldman-sachs.html (last accessed: 25 July 2022).", "matched_news_url": "https://www.nytimes.com/2019/11/15/us/apple-card-goldman-sachs.html", "matched_news_outlet": "The New York Times"}, {"reference_string": "5. Amazon scraps secret AI recruiting tool that showed bias against women, Reuters, 11 October 2018, available at: https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G (last accessed: 25 July 2022).", "matched_news_url": "https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G", "matched_news_outlet": "Reuters"}, {"reference_string": "3. Melissa Heikkila, Dutch scandal serves as a warning for Europe over risks of using algorithms, Politico, 29 March 2022, available at: https://www.politico.eu/article/dutch-scandal-servesas-a-warning-for-europe-over-risks-of-using-algorithms/ (last accessed: 30 August 2022)", "matched_news_url": "https://www.politico.eu/article/dutch-scandal-servesas-a-warning-for-europe-over-risks-of-using-algorithms/", "matched_news_outlet": "Politico"}, {"reference_string": "63. Jon Henley, \u201cDutch government faces collapse over child benefits scandal\u201d (14 January 2021) The Guardian available at: https://www.theguardian.com/world/2021/jan/14/dutch-government-faces-collapse-over-child-benefits-scandal and Bj\u00f6rn ten Seldam & Alex Brenninkmeijer, \u201cThe Dutch benefits scandal: a cautionary tale for algorithmic enforcement\u201d (30 April 2021) EU Law Enforcement available at: https://eulawenforcement.com/?p=7941.", "matched_news_url": "https://www.theguardian.com/world/2021/jan/14/dutch-government-faces-collapse-over-child-benefits-scandal", "matched_news_outlet": "The Guardian"}], "people": [{"person": "Kate Crawford", "affiliation": "New York University", "snippet": "109. Sarah Myers West, Meredith Whittaker and Kate Crawford, Discriminating Systems: Gender,\nRace, and Power in AI, AI Now Institute NYU, April 2019, available at: https://ainowinstitute.\norg/discriminatingsystems.pdf (last accessed: 27 July 2022)."}, {"person": "Meredith Whittaker", "affiliation": "New York University", "snippet": "109. Sarah Myers West, Meredith Whittaker and Kate Crawford, Discriminating Systems: Gender,\nRace, and Power in AI, AI Now Institute NYU, April 2019, available at: https://ainowinstitute.\norg/discriminatingsystems.pdf (last accessed: 27 July 2022)."}]}, "highlights": [{"type": "text", "text": "important to underline thatthe regulatory subject is not AI taken in isolation but rather the broadersocio-technical apparatus constituted by the interaction of social elementswith algorithmic technologies.    13. Ibid.14. EU AI Act, Art. 31.15. See Annex 1 of the EU AI Act: Artificial intelligence techniques and approaches referredto in Article 3, point 1.    16. European Parliament, What is artificial intelligence and how is it used? 2021 availableat: https://www.europarl.europa.eu/new", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=6595d842ae9e6c1ecfd9f976dcb8e058&k=cbe651e0241385f4082a08119f51bc05", "pdf_title": "PDF #1", "page": "15"}, {"type": "text", "text": "policy landscape in Europe  Page 63          EU AI Act. 187 A commonality between the two regulations would be the riskbasedapproach they both adopt to AI systems. 188 Yet the Council of Europehas the potential to foster a distinct human-rights-based approach to AIand algorithmic technologies.    Sectoral regulation of AI is also currently underway in the EU. The draft EUAI Act follows a risk-based approach and classifies AI systems as high-riskif they are deployed", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=6595d842ae9e6c1ecfd9f976dcb8e058&k=cbe651e0241385f4082a08119f51bc05", "pdf_title": "PDF #1", "page": "64"}, {"type": "text", "text": "limited risk are subjected to specific transparency obligations andthose with low or minimal risk to codes of conduct.    Although the EU AI Act foresees promising transparency obligations with aview to bias mitigation, in particular in relation to training data and decisioncriteria, 189 several criticisms have been put forward regarding the way in whichthe EU AI Act proposes to ensure that fundamental rights are respected. Forexample, it approaches AI systems from a product liability perspective andthus", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=6595d842ae9e6c1ecfd9f976dcb8e058&k=cbe651e0241385f4082a08119f51bc05", "pdf_title": "PDF #1", "page": "65"}, {"type": "text", "text": "sectors,but with an emphasis on employment and education. Finally, the Studyfocuses on the legal context and instruments of the Council of Europe, butaligns with and complements the risk-based approach adopted by the EuropeanUnion in its proposed EU AI Act.    10. See Frederik Borgesius, Discrimination, Artificial Intelligence and Algorithmic Decision-Making 2018 Council of Europe available at: https://rm.coe.int/discrimination-artificial-intelligence-and-algorithmic-decision-making/1680925d73.See", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=6595d842ae9e6c1ecfd9f976dcb8e058&k=cbe651e0241385f4082a08119f51bc05", "pdf_title": "PDF #1", "page": "13"}, {"type": "text", "text": "Possible elements of a legal framework on artificialintelligence, based on the Council of Europes standards on human rights, democracy andthe rule of law, Council of Europe 2022, 19.189. See in particular Art. 10 on Data and data governance of the EU AI Act.190. See Joan Lopez Solano, Aaron Martin, Siddharth de Souza and Linnet Taylor, Governingdata and artificial intelligence for all Models for sustainable and just data governance Panelfor the Future of Science and Technology, European Parliamentary", "pdf_url": "https://edoc.coe.int/en/module/ec_addformat/download?cle=6595d842ae9e6c1ecfd9f976dcb8e058&k=cbe651e0241385f4082a08119f51bc05", "pdf_title": "PDF #1", "page": "65"}]}
